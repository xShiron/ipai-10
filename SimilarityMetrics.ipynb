{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the datasets.\n",
    "The accidents dataset is only with 10000 columns for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollution = pd.read_csv(\"pollution_2000_2023.csv\")\n",
    "nba = pd.read_csv(\"nba_elo.csv\")\n",
    "accidents = pd.read_csv(\"US_Accidents_March23.csv\", nrows = 10000)\n",
    "teams = pd.read_csv(\"team.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Accident_City Pollution_City  Jaccard_Similarity\n",
      "24756            PITTSBURG      PITTSBURG            1.000000\n",
      "11034               NEWARK         NEWARK            1.000000\n",
      "959              JOHNSTOWN      JOHNSTOWN            1.000000\n",
      "13615            CUPERTINO      CUPERTINO            1.000000\n",
      "14553              CONCORD        CONCORD            1.000000\n",
      "13076              VALLEJO        VALLEJO            1.000000\n",
      "22955            SAN PABLO      SAN PABLO            1.000000\n",
      "7059               BURBANK        BURBANK            1.000000\n",
      "13763             SAN JOSE       SAN JOSE            1.000000\n",
      "26800             BERKELEY       BERKELEY            1.000000\n",
      "60625            DAVENPORT      DAVENPORT            1.000000\n",
      "32541              JACKSON        JACKSON            1.000000\n",
      "37751              BENICIA        BENICIA            1.000000\n",
      "13970        SAN FRANCISCO  SAN FRANCISCO            1.000000\n",
      "5222            WILMINGTON     WILMINGTON            1.000000\n",
      "32028             CROCKETT       CROCKETT            1.000000\n",
      "15077              OAKLAND        OAKLAND            1.000000\n",
      "4326             CLEVELAND      CLEVELAND            1.000000\n",
      "25970  SOUTH SAN FRANCISCO  SAN FRANCISCO            0.666667\n",
      "4354                BETHEL  BETHEL ISLAND            0.500000\n",
      "28955           SAN CARLOS      SAN PABLO            0.333333\n",
      "17602           MENLO PARK      PARK HILL            0.333333\n",
      "18352        PLEASANT HILL      PARK HILL            0.333333\n",
      "36833            YUBA CITY   BOULDER CITY            0.333333\n",
      "56861           MOSS BEACH     LONG BEACH            0.333333\n",
      "12544         NEW CARLISLE      NEW HAVEN            0.333333\n",
      "18233           UNION CITY   BOULDER CITY            0.333333\n",
      "26368         CAMERON PARK      DEER PARK            0.333333\n",
      "22970            SAN PABLO  SAN FRANCISCO            0.333333\n",
      "22969            SAN PABLO      SAN DIEGO            0.333333\n",
      "30170          SAN LORENZO  SAN FRANCISCO            0.333333\n",
      "27820           EL CERRITO        EL PASO            0.333333\n",
      "19570            EL DORADO        EL PASO            0.333333\n",
      "28969           SAN CARLOS      SAN DIEGO            0.333333\n",
      "47063          SAN ANDREAS       SAN JOSE            0.333333\n",
      "31028            DALY CITY  OKLAHOMA CITY            0.333333\n",
      "23333         REDWOOD CITY   BOULDER CITY            0.333333\n",
      "35270           SAN RAFAEL  SAN FRANCISCO            0.333333\n",
      "35269           SAN RAFAEL      SAN DIEGO            0.333333\n",
      "40762         SAN GREGORIO    SAN ANTONIO            0.333333\n",
      "13669             SAN JOSE      SAN DIEGO            0.333333\n",
      "13670             SAN JOSE  SAN FRANCISCO            0.333333\n",
      "26513            SAN BRUNO       SAN JOSE            0.333333\n",
      "29362            SAN RAMON    SAN ANTONIO            0.333333\n",
      "26512            SAN BRUNO    SAN ANTONIO            0.333333\n",
      "59933          SIERRA CITY   BOULDER CITY            0.333333\n",
      "45760            LOS BANOS    LOS ANGELES            0.333333\n",
      "13762             SAN JOSE    SAN ANTONIO            0.333333\n",
      "2828            GROVE CITY  OKLAHOMA CITY            0.333333\n",
      "34968         MEADOW VISTA    CHULA VISTA            0.333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import jaccard_score\n",
    "# Preprocess\n",
    "accidents[\"City\"] = accidents[\"City\"].str.upper().str.strip()\n",
    "pollution[\"City\"] = pollution[\"City\"].str.upper().str.strip()\n",
    "\n",
    "accident_cities = accidents[\"City\"].dropna().unique()\n",
    "pollution_cities = pollution[\"City\"].dropna().unique()\n",
    "\n",
    "# Set up vectorizer\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "\n",
    "similarity_scores = []\n",
    "\n",
    "for city_a in accident_cities:\n",
    "    for city_b in pollution_cities:\n",
    "        # Fit and transform both cities into binary vectors\n",
    "        vec = vectorizer.fit_transform([city_a, city_b]).toarray()\n",
    "        # Compute Jaccard similarity on the binary vectors\n",
    "        score = jaccard_score(vec[0], vec[1])\n",
    "        similarity_scores.append((city_a, city_b, score))\n",
    "\n",
    "# Convert to DataFrame\n",
    "similarity_df = pd.DataFrame(similarity_scores, columns=[\"Accident_City\", \"Pollution_City\", \"Jaccard_Similarity\"])\n",
    "print(similarity_df.sort_values(by=\"Jaccard_Similarity\", ascending=False).head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting DataFrame displays the top 50 city name pairs from the accidents and pollution datasets with the highest Jaccard similarity scores.\n",
    "A Jaccard similarity close to 1 indicates that the city names are nearly identical (e.g., \"LOS ANGELES\" vs. \"LOS ANGELES\"), while lower scores suggest partial matches.\n",
    "These results are useful for identifying and potentially aligning city names that refer to the same place but may have been written differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2        3         4\n",
      "0  0.000000  0.333477  0.333450  0.01763  0.333450\n",
      "1  0.333477  0.000000  0.018609  0.33446  0.018609\n",
      "2  0.333450  0.018609  0.000000  0.33345  0.000000\n",
      "3  0.017630  0.334460  0.333450  0.00000  0.333450\n",
      "4  0.333450  0.018609  0.000000  0.33345  0.000000\n"
     ]
    }
   ],
   "source": [
    "# Filter and normalize the relevant columns\n",
    "features = accidents[[\"Severity\", \"Temperature(F)\"]].dropna()\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Compute Euclidean distance between all rows\n",
    "distance_matrix = squareform(pdist(scaled_features, metric=\"euclidean\"))\n",
    "\n",
    "# Put into a DataFrame for readability\n",
    "euclidean_df = pd.DataFrame(distance_matrix, index=features.index, columns=features.index)\n",
    "print(euclidean_df.iloc[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting DataFrame displays the pairwise Euclidean distances between accident records based on their normalized 'Severity' and 'Temperature(F)' values.\n",
    "A smaller distance (closer to 0) indicates a higher similarity between two events in terms of accident severity and the temperature at which they occurred.\n",
    "For example, a distance of 0.017 means that the two incidents occurred under nearly identical conditions.\n",
    "These results can be useful for identifying clusters or patterns in accidents that share similar characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            2016-02-08 05:46:00  2016-02-08 06:07:59  2016-02-08 06:49:27  \\\n",
      "2000-01-01             0.708563             0.717924             0.721959   \n",
      "2000-01-02             0.699723             0.715317             0.721630   \n",
      "2000-01-03             0.831177             0.847566             0.842922   \n",
      "2000-01-04             0.860439             0.873117             0.867923   \n",
      "2000-01-05             0.818031             0.833741             0.822241   \n",
      "\n",
      "            2016-02-08 07:23:34  2016-02-08 07:39:07  \n",
      "2000-01-01             0.720223             0.700232  \n",
      "2000-01-02             0.712014             0.692894  \n",
      "2000-01-03             0.835503             0.829900  \n",
      "2000-01-04             0.865262             0.857588  \n",
      "2000-01-05             0.818917             0.818355  \n"
     ]
    }
   ],
   "source": [
    "# Select pollution and weather features\n",
    "pollution_features = pollution[[\"O3 Mean\", \"SO2 Mean\", \"CO Mean\", \"NO2 Mean\"]].dropna()\n",
    "\n",
    "# Updated: Extract weather features from the accidents dataset\n",
    "weather_features = accidents[[\"Temperature(F)\", \"Humidity(%)\", \"Wind_Speed(mph)\", \"Pressure(in)\"]].dropna()\n",
    "\n",
    "# Match the number of rows for alignment (optional, here taking the minimum)\n",
    "min_len = min(len(pollution_features), len(weather_features))\n",
    "pollution_features = pollution_features.iloc[:min_len]\n",
    "weather_features = weather_features.iloc[:min_len]\n",
    "\n",
    "# Normalize both datasets\n",
    "scaler = MinMaxScaler()\n",
    "pollution_scaled = scaler.fit_transform(pollution_features)\n",
    "weather_scaled = scaler.fit_transform(weather_features)\n",
    "\n",
    "# Compute Cosine Similarity\n",
    "cos_sim_matrix = cosine_similarity(pollution_scaled, weather_scaled)\n",
    "\n",
    "# Extract identifying columns\n",
    "pollution_ids = pollution.iloc[:min_len][\"Date\"].astype(str).values\n",
    "weather_ids = accidents.iloc[:min_len][\"Start_Time\"].astype(str).values\n",
    "\n",
    "# Create labeled DataFrame\n",
    "cos_sim_df = pd.DataFrame(cos_sim_matrix, index=pollution_ids, columns=weather_ids)\n",
    "\n",
    "# Show the top left corner\n",
    "print(cos_sim_df.iloc[:5, :5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting DataFrame displays the pairwise cosine similarities between pollution records (rows) and weather condition records (columns) based on their normalized values for pollutants (O3 Mean, SO2 Mean, CO Mean, NO2 Mean) and weather metrics (Temperature(F), Humidity(%), Wind_Speed(mph), Pressure(in)).\n",
    "\n",
    "Each cell represents how similar the environmental conditions were on a specific pollution measurement date compared to a specific accident weather record. A value closer to 1 indicates a stronger alignment in the pattern of values across the features, even if their absolute magnitudes differ.\n",
    "\n",
    "For instance, a cosine similarity of 0.94 means that the pollution and weather values on those specific days followed a very similar directional trend across all measured features. This allows you to detect consistent environmental profiles or match pollution conditions with real accident-time weather data.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
